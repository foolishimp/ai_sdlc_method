# AI SDLC — Evaluator Defaults
# Implements: REQ-EVAL-002 (Evaluator Composition Per Edge), REQ-EVAL-003 (Human Accountability)
# Version: 2.6.0
# Reference: AISDLC_IMPLEMENTATION_REQUIREMENTS.md REQ-EVAL-001, REQ-EVAL-002, REQ-EVAL-003
#
# Defines the three evaluator types and their default behaviour.
# Edge parameterisations can override these defaults.

---

evaluator_types:

  human:
    type: human
    processing_phase: conscious
    processing_phases: [conscious]
    description: "Human judgment — approval, rejection, or refinement guidance"
    mechanism: |
      Present the current asset candidate to the user.
      Ask for explicit approval, rejection, or refinement instructions.
      Record the human's decision and any feedback in iteration history.
    convergence: "User explicitly approves the asset"
    accountability: |
      AI assists, human decides. The human evaluator is the authority
      on all edges where human_required is true. The iterate agent
      NEVER auto-approves on behalf of the human.

  agent:
    type: agent
    processing_phase: conscious
    processing_phases: [conscious]    # Deliberative. Agent also emits affect (valence) on its gap findings, but affect is not an evaluator assignment — all evaluators emit affect.
    description: "LLM-based assessment — coherence, completeness, gap analysis"
    mechanism: |
      Assess the current asset candidate against:
      - Source asset coherence (does it faithfully represent the source?)
      - Completeness (are all acceptance criteria addressed?)
      - Consistency (does it align with Context[]?)
      - Gap analysis (what's missing or inconsistent?)
    convergence: "No gaps detected, all criteria met, agent confirms quality"
    delta_report: |
      When delta > 0, provide specific, actionable feedback:
      - What is missing
      - What is inconsistent
      - What needs refinement
      - Suggested next action

  deterministic:
    type: deterministic
    processing_phase: reflex
    processing_phases: [reflex]
    description: "Automated checks — tests, schemas, linters, format validators"
    mechanism: |
      Run or invoke automated validation:
      - Compilation/parsing
      - Test execution (unit, integration, BDD)
      - Schema validation
      - Lint/style checks
      - REQ key tag presence and format
    convergence: "All checks pass"
    result_format: |
      Binary: pass/fail for each check.
      On failure, report:
      - Which check failed
      - The specific error
      - Remediation guidance

---

# ═══════════════════════════════════════════════════════════════════════
# CHECKLIST FORMAT
# ═══════════════════════════════════════════════════════════════════════
#
# Edge configs define evaluator checks as structured checklist entries.
# Each check is ONE evaluable condition. The iterate agent counts pass/fail
# and reports "N of M required checks pass" with details on failures.
#
# Check entry schema:
#
#   - name: string               # unique identifier for this check
#     type: enum                  # agent | deterministic | human
#     criterion: string           # what "pass" means (readable by the LLM)
#     source: enum                # default | project | feature
#     required: bool              # true = blocks convergence, false = advisory
#     command: string             # (deterministic only) shell command to run
#     pass_criterion: string      # (deterministic only) how to interpret result
#
# $variable references resolve from project_constraints.yml:
#   $tools.{name}.{field}    → project tools configuration
#   $thresholds.{key}        → project numeric thresholds
#   $standards.{key}         → project qualitative standards
#   $architecture.{key}      → project architecture constraints
#
# Composition rules:
#   1. Edge checklist defines default checks
#   2. $variables resolve from project_constraints.yml
#   3. Feature threshold_overrides apply on top
#   4. Feature acceptance_criteria append to checklist
#   5. Feature additional_checks append to checklist
#   6. required=true at any layer stays true (most restrictive wins)
#   7. Unresolved $variables → check SKIPPED with warning
#
# Delta = count of failing required checks
# Convergence = delta == 0

---

# Convergence composition rules
convergence_rules:
  # All evaluators on an edge must pass for convergence
  composition: "all_must_pass"

  # Order matters: run evaluators in the order specified in edge config
  # Typically: agent first (cheapest), then deterministic, then human (most expensive)
  ordering: "as_specified_in_edge_config"

  # If any evaluator fails, report the failure and suggest the next iteration
  on_failure: "report_delta_and_iterate"

  # Human evaluator is always last when present (reviews agent + deterministic results)
  human_always_last: true

---

# ═══════════════════════════════════════════════════════════════════════
# PROCESSING PHASES (Spec §4.3)
# ═══════════════════════════════════════════════════════════════════════
#
# Three processing phases govern all methodology operations. Each phase
# enables the next: reflexes produce the sensory substrate, affect attaches
# valence to findings, consciousness directs from what affect escalates.

processing_phases:

  reflex:
    description: "Autonomic sensing — fires unconditionally, no judgment"
    includes:
      - deterministic tests
      - event emission to events.jsonl
      - feature vector state update
      - STATUS.md regeneration
      - protocol enforcement hooks
      - circuit breaker activation
    fires_when: "Every iteration boundary, every edge — no exceptions, no decision"

  affect:
    description: "Valence vector on gap findings — urgency, severity, priority"
    # Affect is NOT an evaluator type. It is emitted by ANY evaluator that
    # finds a gap: F_D emits severity via threshold breach, F_P via classified
    # urgency, F_H via human priority judgment. The affect signal determines
    # routing — defer or escalate.
    includes:
      - signal source classification (gap / discovery / ecosystem / optimisation / user / TELEM)
      - severity and priority weighting
      - escalation decision (escalate to conscious vs log-and-defer)
      - threshold tuning per projection profile
    fires_when: "Any evaluator detects a gap — attaches valence to the finding"
    emitted_by: "F_D (threshold breach), F_P (classified severity), F_H (human urgency judgment)"

  conscious:
    description: "Deliberative processing — requires judgment"
    includes:
      - human evaluator
      - agent evaluator (deliberative)
      - gap assessment and interpretation
      - intent generation from deltas
      - spec modification
      - spawn decisions
      - convergence judgment (question_answered)
    fires_when: "Affect determines signal warrants deliberation — approval, design, intent"
