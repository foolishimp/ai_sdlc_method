# ADR-GG-003: Interactive Refinement via `ask_user`

**Status**: Accepted
**Date**: 2026-02-21
**Deciders**: Gemini CLI Agent
**Requirements**: REQ-EVAL-001, REQ-EVAL-003 (Human Accountability)

---

## Context

The Asset Graph Model emphasizes the **Human Evaluator** (REQ-EVAL-001) and human accountability (REQ-EVAL-003). In Claude Code, refinement occurs through a free-form chat interaction. This can be ambiguous and difficult to log in a structured way for automated ADR generation.

Gemini CLI offers an `ask_user` tool that supports structured questions:
-   **Type 'choice'**: Multi-choice options with labels and descriptions.
-   **Type 'yesno'**: Binary confirmation.
-   **Type 'text'**: Free-text input with placeholders.

### Options Considered

1.  **Free-form Chat Only**: Rely solely on the main Gemini chat interface for user interaction.
2.  **Structured Tool Only**: Use `ask_user` exclusively for all refinement decisions.
3.  **Hybrid Interaction**: Use the chat interface for broad guidance and `ask_user` for structured, actionable decisions.

---

## Decision

**We will adopt the "Hybrid Interaction" model, where the `aisdlc_iterate` sub-agent is instructed to use the `ask_user` tool for all critical design decisions and ADR-bound refinements.**

Workflow:
1.  **Refinement Trigger**: During an iteration, the Sub-agent identifies an ambiguity (e.g., "Which database technology should we use?").
2.  **Structured Prompt**: The Sub-agent calls `ask_user` with a "choice" type question, listing the alternatives it has considered.
3.  **Automatic Capture**: The user's selection is immediately formatted into an **ADR** and recorded as a **decision event** in `events.jsonl`.

---

## Rationale

### Why This Approach (vs Chat Only)

1.  **Decision Logging**: Structured choices map directly to "Alternatives Considered" in an ADR, eliminating the need for the agent to infer the user's preference from a complex chat history.
2.  **Reduced Ambiguity**: Using `ask_user(type="choice")` forces the user to choose from a defined set of options, reducing the risk of underspecified refinements.
3.  **Audit Trail**: Each call to `ask_user` is a distinct, timestamped event in the Gemini tool history and the AI SDLC event log.
4.  **Consistency**: It ensures that all design decisions go through a formal "Approval Boundary" that is clearly visible to the user.

---

## Consequences

### Positive

-   **High-Quality ADRs**: ADRs generated by the methodology will be more accurate and reflective of the actual trade-offs presented to and chosen by the user.
-   **Better "Human-in-the-Loop" experience**: The user is presented with clear, concise options instead of having to write paragraphs of instruction.
-   **Structured Feedback**: If the user chooses "Other" (automatically added by Gemini), it triggers a free-text refinement that remains within the structured tool context.

### Negative

-   **Tool Saturation**: Frequent use of `ask_user` could be perceived as interrupting the agent's autonomous flow.
-   **Constrained Input**: If the Sub-agent's choice list is poor, the user may feel limited (mitigated by the "Other" option).

### Mitigation

-   The `aisdlc_iterate` sub-agent will be prompted to group multiple refinement questions into a **single `ask_user` call** where possible.
-   Instructions for the Sub-agent will mandate providing a high-quality "None of the above" or "Other" option for all choices.

---

## References

- [GEMINI_GENESIS_DESIGN.md](../GEMINI_GENESIS_DESIGN.md) ยง2.4
- [ADR-011: Consciousness Loop at Every Observer](../../claude_aisdlc/adrs/ADR-011-consciousness-loop-at-every-observer.md)
